import os
import pprint
import shutil
from pathlib import Path
from datetime import datetime, timedelta

from airflow import DAG
from airflow.settings import EDA_HOME, DAGS_FOLDER
from airflow.operators.dag_operator import DagOperator
from airflow.operators.bash_operator import BashOperator
from airflow.operators.python_operator import PythonOperator
from airflow.api.common.experimental.delete_dag import delete_dag

pp = pprint.PrettyPrinter(indent=4)

classPath = 'ai.couture.obelisk.eda.MainClass'
appName = 'EDAVisualisations'
code_artifact = 'obelisk-eda.jar'

folder_to_copy_summary = '{{folder_to_copy_sum}}'

# path in container where intermediate data is dumped
data_dump_dir = Path(EDA_HOME).joinpath(*["inputs", folder_to_copy_summary, "preliminary"])

# folders containing table_info and preliminary_summary inside data_dump_dir
data_dump_dir_1 = data_dump_dir.joinpath("table_info")
data_dump_dir_2 = data_dump_dir.joinpath("preliminary_summary")

# file where visualizations will be dumped.
viz_dump_path = Path(EDA_HOME).joinpath(
    *["outputs",
    {% for output_dir in output_dirs %}
    "{{output_dir}}",
    {% endfor %}
    "data_info.html"])


def mkdir_dirs(ds, **kwargs):
    # create paths to input output if not exists
    data_dump_dir.mkdir(parents=True, exist_ok=True)
    viz_dump_path.parent.mkdir(parents=True, exist_ok=True)


# how to cleanup when run failed ?
def cleanup_dirs(ds, **kwargs):
    shutil.rmtree(data_dump_dir.parent)


def remove_dags(ds, **kwargs):
    # remove the dags files, then remove from database.
    os.remove(os.path.join(DAGS_FOLDER, '{{dag_id}}.py'))
    os.remove(os.path.join(DAGS_FOLDER, '{{summ_dag_id}}.py'))
    delete_dag('{{summ_dag_id}}')
    delete_dag('{{dag_id}}')


default_args = {
    'owner': '{{username}}',
    'depends_on_past': False,
    'start_date': datetime({{now.year}}, {{now.month}}, {{now.day}}),
    'retries': 0,
}

EDADag = DAG(
    '{{dag_id}}',
    default_args=default_args,
    schedule_interval='@once')

EDAPreliminaryCreateDirs = PythonOperator(
    task_id='EDAPreliminaryCreateLocalDumpDirs',
    provide_context=True,
    python_callable=mkdir_dirs,
    dag=EDADag
)

EDAPreliminaryRemoveDirs = PythonOperator(
    task_id='EDAPreliminaryRemoveLocalDumpDirs',
    provide_context=True,
    python_callable=cleanup_dirs,
    dag=EDADag
)

EDAPreliminaryDataSummary = DagOperator(
    task_id='EDAPreliminaryDataSummary',
    run_dag_id='{{summ_dag_id}}',
    dag=EDADag,
    description=''
)

EDAPreliminaryVisualisation = BashOperator(
    task_id='EDAPreliminaryVisualisation',
    dag=EDADag,
    description='EDAPreliminaryVisualisation',
    bash_command='python3 {} {} {} {}'.format(
        Path(EDA_HOME).joinpath(*['codes', 'preliminary_visualisation.py']),
        data_dump_dir_1,
        data_dump_dir_2,
        viz_dump_path)
)

EDAPreliminaryRemoveDAGs = PythonOperator(
    task_id='EDAPreliminaryRemoveDAGs',
    provide_context=True,
    python_callable=remove_dags,
    dag=EDADag
)

# hdfs dfs -get source/path dest/path
EDAPreliminaryDataSummary.set_upstream(EDAPreliminaryCreateDirs)
EDAPreliminaryVisualisation.set_upstream(EDAPreliminaryDataSummary)
EDAPreliminaryRemoveDirs.set_upstream(EDAPreliminaryVisualisation)
EDAPreliminaryRemoveDAGs.set_upstream(EDAPreliminaryRemoveDirs)
